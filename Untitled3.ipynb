{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNybk6zTqgwDRgsZiJxQnsC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kim3691477/ai/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f56IgCP7U3r",
        "colab_type": "text"
      },
      "source": [
        "4주차 1강 - 딥러닝\n",
        "\n",
        "딥러닝 - 인간의 신경망 이론을 이용한 인공신경망의 일종으로 계층 구조로 구성되며 입력층과 출력층 사이에 하나 이상의 은닉층을 가지고 있는 심층 신경망\n",
        "\n",
        "인공 신경망 - 인간의 뇌 구조를 모방하여 모델링한 수학적 모델\n",
        "신경세포인 뉴런과 시냅스 혹은 가중치인 연결로 구분\n",
        "노드들을 연결시키고 층을 만들며, 이러한 연결 강도는 가중치로 처리\n",
        "\n",
        "신경세포 - 뉴런의 입력은 다수이고, 출력은 하나이며, 여러 신경세포로부터 전달되어 온 신호들이 합산되어 출력\n",
        "\n",
        "출력 - 합산된 값이 설정값 이상이면 출력 신호가 생기고, 이하이면 출력 신호가 생기지 않음\n",
        "\n",
        "수상돌기<->입력\n",
        "세포체(노드)<->입력합산 지점\n",
        "축삭<->출력\n",
        "\n",
        "시냅스 - 다수의 뉴련을 연결해주는 역할\n",
        "\n",
        "인공신경망의 공통적으로 이야기 되는 시점\n",
        "1957년 프랭크 로젠블랫에 의해 고안된 Perceptron -> 1969년 Multilayer perceptron -> 1986년 Backpropagation -> 1992년 Recurrent Neural Network -> 1998년 손글씨 문자인식 연구 -> 2000년 딥러닝 용어 등장 -> 2012년 Drop Out 알고리즘\n",
        "\n",
        "딥려닝\n",
        "이미지 인식 - 합성곱 신경망(CNN)\n",
        "음성 혹은 글자 - 순환 신경망(RNN)은 이후 LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit)으로 발전\n",
        "\n",
        "1. 딥러닝은 인간의 신경망 이론을 이용하여 계층 구조로 구성된 세 개의 층을 가지고 있는 _ _ _ _ _이다.\n",
        "- 심층신경망\n",
        "\n",
        "2. 음성과 글자의 경우 길이가 가변적이고 말의 문맥을 파악해야 한다는 점에서 CNN 보다는 순환신경망이 더 적합하다.\n",
        "- O\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHDw6I8CKqSA",
        "colab_type": "text"
      },
      "source": [
        "4주차 2강 - 딥러닝 원리[1]\n",
        "\n",
        "초창기 머신러닝\n",
        "1943년 워랜 맥컬록과 월터 피츠는 간소화된 뇌의 뉴런 개념을 처음으로 발표(맥컬록-피츠 뉴런(MCP)) \n",
        "신경세포를 이진 출력을 내는 간단한 논리 회로로 표현\n",
        "\n",
        "프래크 로젠 블랫은 MCP를 기반으로 Perceptron 발표\n",
        "자동으로 최적의 가중치를 학습하는 알고리즘을 제안\n",
        "이 가중치는 뉴런의 출력 신호를 낼지 말지를 결정하기 위해 입력 특성에 곱하는 계수가 됨\n",
        "\n",
        "활성화 함수(뉴런의 출력값을 정함) - 가장 간단한 형태의 뉴런은 입력에 가중치를 곱한 뒤, 활성화 함수를 취하면 출력 값을 얻을 수 있음\n",
        "\n",
        "뉴런에서 학습할 때 변하는 것(w값)은 가중치 - 처음에 초기화를 통해 무자위 값을 넣고 학습과정에서 일정한 값 수렴\n",
        "학습이 잘 된다는 것은, 좋은 가중치를 얻어 원하는 출력에 점점 가까워지는 값을 얻는 것이라 할 수 있음\n",
        "\n",
        "입력x ----------> 활성화함수f(x)->출력y\n",
        "       (가중치w)\n",
        "\n",
        "y=f(x*w)\n",
        "\n",
        "error(우리가 기대한 값과 실제 출력값의 차이) = 기대출력(0) - 실제출력(0.474...)\n",
        "\n",
        "w = w+x* 학습률(가중치 조정을 위한 하이퍼파라미터)*error\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-7X3D_1MvIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "c0856dc9-7931-4d00-8d98-86fa016aaaff"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1],0,1)\n",
        "#0과는 거리가 먼 값이 나온 이유 : 가중치를 무작위로 선정\n",
        "#이 가중치는 우리가 구하려는 가중치 값이 아님을 의미\n",
        "\n",
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + math.exp(-x))\n",
        "\n",
        "output = sigmoid(x*w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x*w)\n",
        "  error = y - output\n",
        "  #이 error가 0에 가까워지도록 가중치를 조절해야하는 데 조절방법으로 경사하강법을 사용\n",
        "  w = w + x* 0.1 * error\n",
        "#경사하강법\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"학습 횟수:\", i, \"Error:\",error, \"예측 결과:\",output)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습 횟수: 99 Error: -0.10010598284299604 예측 결과: 0.10010598284299604\n",
            "학습 횟수: 199 Error: -0.05178399422833116 예측 결과: 0.05178399422833116\n",
            "학습 횟수: 299 Error: -0.034590451977903586 예측 결과: 0.034590451977903586\n",
            "학습 횟수: 399 Error: -0.02588962752851373 예측 결과: 0.02588962752851373\n",
            "학습 횟수: 499 Error: -0.020658699939863617 예측 결과: 0.020658699939863617\n",
            "학습 횟수: 599 Error: -0.017174253993457355 예측 결과: 0.017174253993457355\n",
            "학습 횟수: 699 Error: -0.014689506449480992 예측 결과: 0.014689506449480992\n",
            "학습 횟수: 799 Error: -0.012829497265431342 예측 결과: 0.012829497265431342\n",
            "학습 횟수: 899 Error: -0.011385568271837804 예측 결과: 0.011385568271837804\n",
            "학습 횟수: 999 Error: -0.010232493309882492 예측 결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpA89PFkOb8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "3527df1f-91f5-4e68-f21f-bf0402af6d5f"
      },
      "source": [
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 0\n",
        "y = 1\n",
        "w = tf.random.normal([1],0,1)\n",
        "\n",
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + math.exp(-x))\n",
        "\n",
        "output = sigmoid(x*w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x*w)\n",
        "  error = y - output\n",
        "  w = w + x* 0.1 * error\n",
        "  #입력값에 0이 들어간 순간부터 가중치 조정이 안됨\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"학습 횟수:\", i, \"Error:\",error, \"예측 결과:\",output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "학습 횟수: 99 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 199 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 299 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 399 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 499 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 599 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 699 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 799 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 899 Error: 0.5 예측 결과: 0.5\n",
            "학습 횟수: 999 Error: 0.5 예측 결과: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z99Y3okROz0t",
        "colab_type": "text"
      },
      "source": [
        "이러한 경우를 방지하고자 편향이란 개념이 등장\n",
        "\n",
        "편향 - 입력으로는 늘 한쪽으로 치우 처진 고정 값\n",
        "입력으로 받은 값이 0인 경우에 아무것도 학습하지 못하는 경우를 방지\n",
        "가중치처럼 난수로 초기화되며 뉴런에 더해져 출력을 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T53SdS8FPKxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "33f2be90-fdb1-4ca7-80ed-3f9b8b3e185e"
      },
      "source": [
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 0\n",
        "y = 1\n",
        "w = tf.random.normal([1],0,1)\n",
        "b = tf.random.normal([1],0,1)\n",
        "#b는 편향\n",
        "\n",
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + math.exp(-x))\n",
        "\n",
        "output = sigmoid(x*w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x*w+1*b)\n",
        "  error = y - output\n",
        "  w = w + x* 0.1 * error\n",
        "  b = b + 1 * 0.1 * error  \n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"학습 횟수:\", i, \"Error:\",error, \"예측 결과:\",output)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "학습 횟수: 99 Error: 0.09463240539328144 예측 결과: 0.9053675946067186\n",
            "학습 횟수: 199 Error: 0.05020774581485887 예측 결과: 0.9497922541851411\n",
            "학습 횟수: 299 Error: 0.03386821893903158 예측 결과: 0.9661317810609684\n",
            "학습 횟수: 399 Error: 0.0254795475417523 예측 결과: 0.9745204524582477\n",
            "학습 횟수: 499 Error: 0.020395445115306998 예측 결과: 0.979604554884693\n",
            "학습 횟수: 599 Error: 0.016991321905264867 예측 결과: 0.9830086780947351\n",
            "학습 횟수: 699 Error: 0.014555195462882198 예측 결과: 0.9854448045371178\n",
            "학습 횟수: 799 Error: 0.01272677569558911 예측 결과: 0.9872732243044109\n",
            "학습 횟수: 899 Error: 0.011304492845635505 예측 결과: 0.9886955071543645\n",
            "학습 횟수: 999 Error: 0.01016688855289749 예측 결과: 0.9898331114471025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ymsVcfPiwA",
        "colab_type": "text"
      },
      "source": [
        "AND OR XOR\n",
        "\n",
        "AND 연산 - 모두 참인 경우만 참, 나머지 경우는 거짓"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIUI9ZadPwX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c2070e13-a933-457a-bf0b-646175af3f8b"
      },
      "source": [
        "#AND연산\n",
        "\n",
        "import numpy as np\n",
        "x= np.array([[1,1],[1,0],[0,1],[0,0]])\n",
        "y = np.array([[1],[0],[0],[0]])\n",
        "w = tf.random.normal([2],0,1)\n",
        "b = tf.random.normal([1],0,1)\n",
        "b_x = 1\n",
        "\n",
        "for i in range(2000):\n",
        "  error_sum = 0\n",
        "  for j in range(4):\n",
        "    output = sigmoid(np.sum(x[j]*w)+b_x*b)\n",
        "    error = y[j][0] - output\n",
        "    w = w + x[j] * 0.1 * error\n",
        "    b = b + b_x * 0.1 * error\n",
        "    error_sum += error\n",
        "\n",
        "for i in range(4):\n",
        "  print('X', x[i], 'Y', y[i], 'Output', sigmoid(np.sum(x[i]*w)+b))\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X [1 1] Y [1] Output 0.9656552933187175\n",
            "X [1 0] Y [0] Output 0.024343040768257922\n",
            "X [0 1] Y [0] Output 0.02441574030056751\n",
            "X [0 0] Y [0] Output 2.2208070794949216e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JIN9zs9QuWh",
        "colab_type": "text"
      },
      "source": [
        "OR 연산 - AND 연산과는 반대로, 모든 입력값이 거짓일 때만 거짓을 출력하고, 나머지 입력에 대해서는 모두 참을 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvN68f-rQ9jP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4fc735f2-50f5-4e3d-e004-81d8ae58f868"
      },
      "source": [
        "#OR 연산\n",
        "\n",
        "import numpy as np\n",
        "x= np.array([[1,1],[1,0],[0,1],[0,0]])\n",
        "y = np.array([[0],[1],[1],[1]])\n",
        "w = tf.random.normal([2],0,1)\n",
        "b = tf.random.normal([1],0,1)\n",
        "b_x = 1\n",
        "\n",
        "for i in range(2000):\n",
        "  error_sum = 0\n",
        "  for j in range(4):\n",
        "    output = sigmoid(np.sum(x[j]*w)+b_x*b)\n",
        "    error = y[j][0] - output\n",
        "    w = w + x[j] * 0.1 * error\n",
        "    b = b + b_x * 0.1 * error\n",
        "    error_sum += error\n",
        "\n",
        "for i in range(4):\n",
        "  print('X', x[i], 'Y', y[i], 'Output', sigmoid(np.sum(x[i]*w)+b))\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X [1 1] Y [0] Output 0.03472762358315398\n",
            "X [1 0] Y [1] Output 0.9753880567743127\n",
            "X [0 1] Y [1] Output 0.9753135412407891\n",
            "X [0 0] Y [1] Output 0.9999770227409299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taWakOVwRCV5",
        "colab_type": "text"
      },
      "source": [
        "XOR 연산 - 2개의 입력값이 서로 다를 때 참을 표현 서로 값이 같을때는 거짓"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMLb4mKjRKZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "ca86e37b-4215-4fc6-fcc8-1c76a43dc062"
      },
      "source": [
        "#XOR 연산\n",
        "\n",
        "import numpy as np\n",
        "x= np.array([[1,1],[1,0],[0,1],[0,0]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "w = tf.random.normal([2],0,1)\n",
        "b = tf.random.normal([1],0,1)\n",
        "b_x = 1\n",
        "\n",
        "for i in range(2000):\n",
        "  error_sum = 0\n",
        "  for j in range(4):\n",
        "    output = sigmoid(np.sum(x[j]*w)+b_x*b)\n",
        "    error = y[j][0] - output\n",
        "    w = w + x[j] * 0.1 * error\n",
        "    b = b + b_x * 0.1 * error\n",
        "    error_sum += error\n",
        "\n",
        "for i in range(4):\n",
        "  print('X', x[i], 'Y', y[i], 'Output', sigmoid(np.sum(x[i]*w)+b))\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X [1 1] Y [0] Output 0.5128176323940516\n",
            "X [1 0] Y [1] Output 0.5128176314633411\n",
            "X [0 1] Y [1] Output 0.4999999990686774\n",
            "X [0 0] Y [0] Output 0.49999999813735485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVp-h1nKRPmW",
        "colab_type": "text"
      },
      "source": [
        "단층이 아닌, 다층 퍼셉트론을 활요하게 되면 어느 정도는 문제(참과 거짓으로 분리)가 해결\n",
        "\n",
        "다층 퍼셉트론의 약점 - 파라미터 개수가 많아지면서 적절한 가중치와 편향을 학습하는 것이 어려움\n",
        "제프리 힌튼은 역전파 알고리즘을 제시하며 문제를 깔끔하게 해결\n",
        "\n",
        "parallel distributed processing\n",
        "explorations in the microstructure of cognition\n",
        "1986\n",
        "James McClelland / David E. Rumelhart / Geoffrey Hinton - Backpropagation(역전파 알고리즘)\n",
        "\n",
        "1. 1957년, 프랭크 로젠블랫은 맥컬록-피츠 모델(MCP)을 기반으로 _ _ _ _ _ _ _ _ _ _ 개념을 발표했다.\n",
        "- perceptron\n",
        "\n",
        "2. 경사하강법에서 가중치 조정을 위한 하이퍼파라미터로써 어떻게 설정하느냐에 따라 학습 시간이 달라지는 이것은 무엇인가? _ _ _\n",
        "- 학습률\n",
        "\n",
        "3. 단층 퍼셉트론으로 AND, OR, XOR 문제를 모두 해결 할 수 있다.\n",
        "- X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsthaa0wS-T0",
        "colab_type": "text"
      },
      "source": [
        "4주차 3강 - 딥러닝 원리[2]\n",
        "\n",
        "신경망의 목적 - 손실함수가 최솟값이 때의 파라미터를 찾아 올바른 학습 결과를 내는 것\n",
        "이는 회귀분석과 로지스틱회귀와 기본개념이 같다\n",
        "단 회귀분석에서 사용하는 파라미터의 수보다 신경망에서 사용하는 파라미터의 개수가 더 많은 편\n",
        "\n",
        "역전파(backpropagation)는 뉴런의 가중치를 효율적으로 조정하기 위하여, 거꾸로 무엇인가를 전파하는 방식\n",
        "출력값과 지도 데이터 사이에 생기는 '오차'를 이용해 출력층에서 입력층 쪽으로 가중치를 조정하는 것\n",
        "\n",
        "역전파는 경사하강법을 사용하는 것과 같다\n",
        "손실 함수가 최솟값일 때의 가중치로 원래의 가중치를 조정해야 한다\n",
        "입력값 각각의 손실 함수 전체를 고려해야함\n",
        "특정 입력값에서 손실함수 최솟값은 크게 의미가 없다\n",
        "궁극적인 목표는 모든 입력값을 대상으로 손실 함수가 최솟값일 때의 파라미터를 찾는 것\n",
        "\n",
        "기울기에 대한 변화가 없다가 다시 점차 증가 혹은 감소하는 현상이 보여줄 수 있으며, 마치 심하게 요동치는 파동과도 같은 모습을 보이는 경우가 다수 있기 때문에 기울기가 0에 가깝게 수렴했을 때, 무작정 최솟값이라 단정 짓는 것은 꽤나 위험한 행동\n",
        "\n",
        "E를 각각 전개하여 직접 편미분을 진행하면 꽤나 번거롭기에\n",
        "입력값 각각의 손실 함수를 편미분 한 후 합이 0에 가까운지 확인\n",
        "\n",
        "은닉층 가중치는 은닉층 편향의 변화량에 y를 곱한 값을 빼서 조정\n",
        "\n",
        "역전파 = 역방향 미분\n",
        "\n",
        "역전파 기법의 문제 - 기울기 소멸 문제\n",
        "역전파 알고리즘으로 학습을 진행하는 데 있어, 주로 사용된 활성화 함수는 시그모이드(Sigmoid)와 소프트맥스(Softmax)\n",
        "시그모이드 - 미분의 최대치가 0.3에 불과하며, 여러층을 거칠 수록 기울기는 점차 0에 수렴하게 되는 문제(기울기 소멸 문제)가 발생\n",
        "소프트맥스 - 출력 값으로 확률 벡터를 얻기 위해 사용되었는데, 각 출력 노드의 출력 값을 0에서 1 사이의 값으로 제한\n",
        "최종 출력을 결정하는 데 있어 합리적인 선택이 가능했으나, 출력된 값들이 항상 너무 작은 값을 가지고 있었기에 신경망이 깊어질수록 오차의 기울기가 점차 작아지며, 끝으로 가면 기울기가 소실돼버리면서 가중치 조정이 이뤄지지 않는다는 문제가 발생\n",
        "\n",
        "이를 해결하기 위해 Geoffrey Hinton은 다양한 활성화 함수를 제시하였으나 그중 ReLU라는 활성화 함수를 활용하게 되면\n",
        "어느 정도 문제가 해결됨을 발견\n",
        "\n",
        "ReLU - 입력이 음수일 때는 0을 출력하지만, 양수일 때는 양수값을 그대로 출력\n",
        "\n",
        "1. 출력값과 지도 데이터 사이에 생기는 '오차'를 이용해 출력층에서 입력층 쪽으로 가중치를 조정하는 방법은 무엇인가?\n",
        "1) 순전파\n",
        "2) 역전파\n",
        "3) 로지스틱회귀\n",
        "4) 회귀분석\n",
        "- 2\n",
        "\n",
        "2. 경사하강법에서 기울기가 0이면 반드시 그 지점은 최솟값이 된다.\n",
        "- X\n",
        "\n",
        "3.역전파 기법은 기울기 소멸 문제로 신경망이 깊어지면 깊어질수록 오차의 기울기가 점차 작아지며 기울기가 소실되는 문제가 발생하지만 _ _ _ _ 활성화 함수를 활용하여 어느정도 해결 할 수 있었다.\n",
        "- ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64M3rBQFl0dD",
        "colab_type": "text"
      },
      "source": [
        "4주차 4강 - 강화학습[1]\n",
        "\n",
        "강화학습 - 에이전트라는 존재가 환경과 상호작용하며, 이 환경에는 보상이라는 기준이 있어서 다양한 시행착오를 겪어가며 보상을 최대화 하는 방향으로 학습 진행\n",
        "다양한 시행착오를 통해 학습이 가능하며, 비교적 명확한 보상을 설정할 수 있는 문제를 해결하는데 사용\n",
        "\n",
        "강화학습 = 보상을 최대화하는 의사결정전략, 순차적인 행동들을 알아나가는 방법\n",
        "\n",
        "순차적인 행동들(Markov decision process(MDP)) - 상태 행동, 보상함수 ,상태 변환 확률, 감가율\n",
        "\n",
        "에이전트 - 강화학습에서 의사결정을 맡음\n",
        "\n",
        "환경 - 에이전트의 의사결정을 반영하여, 에이전트에 반영된 정보를 주는 역할\n",
        "\n",
        "상태 - 에이전트는 상태를 기반으로 의사결정을 진행, 의사결정을 하기 위해 사용되는 관측값, 행동, 보상을 가공한 정보\n",
        "\n",
        "행동 - 에이전트가 의사결정을 통해 취할 수 있는 행동\n",
        "일반적으로 현재 상태에서 취하는 행동을 At라고 표기\n",
        "이 행동에는 환경에 따라 결정되는 이산적인 행동과 연속적 행동이 있음\n",
        "이산적 행동 - 에이전트에게 주어지는 행동의 선택지가 있으며, 에이전트는 그 중 하나 선택\n",
        "연속적 행동 - 선택지마다 특정 값을 수치로 입력하게 되고, 에이전트는 입력 값 만큼 움직임\n",
        "\n",
        "관측 - 환경에서 제공해주는 정보, 시각적 관측과 수치적 관측으로 구분\n",
        "시각적 관측 - 현재 상태의 정보를 이미지로 표현한 것\n",
        "수치적 관측 - 이미지의 형태가 아닌, 수치로면 표현\n",
        "\n",
        "보상함수 - 에이전트가 특정 상태에서 특정 행동을 했을 때, 보상을 받게 되고 에이전트는 이 보상정보를 통해 학습을 진행\n",
        "\n",
        "강화학습에서는 에피소드가 끝나게 됐을 때, 에이전트가 지나왔던 상태에서 했던 행동에 대한 정보를 기록\n",
        "그리고 그 정보를 이용하여 그 다음 에피소드에 대한 의사결정\n",
        "그리고 또 에피소드가 끝나면 이 에피소드를 통해 얻게 된 정보로 기록을 업데이트하며 이러한 과정을 반복\n",
        "\n",
        "에이전트는 현재 스텝에서 받았던 보상으로 부터 에피소드가 끝날때 까지 받았던 보상들을 더한 것을 정보로 이용\n",
        "\n",
        "에이전트는 초기상태에서 판단을 못하는 이유는 현재 기록한 정보만으로 효율적인지 알 수 없기 때문이다\n",
        "이 점을 보안하기 위한 감마율이라는 개념이 도입\n",
        "\n",
        "감가율 - 0~1 사이의 값을 설정, 1에 가까울 수록 미래의 보상에 더 많은 가중치를 두게 됨\n",
        "\n",
        "반환값을 기록할 때는 종료된 상태부터 처음 상태까지 거꾸로 계산하는게 좀 더 쉬움\n",
        "반환값을 기록하게 되면, 에이전트는 효율적인 판단을 할 수 있음\n",
        "\n",
        "에이전트에게 무작위로 움직이게 설정하여 여러 경로를 시도해 보라는 '탐험'이라는 개념을 추가\n",
        "'탐험'과 대립되는 개념은 '이용'\n",
        "'이용'은 에이전트가 찾아놓은 길로 하여 계속해서 선택하고 움직이게 되는 것을 의미\n",
        "\n",
        "1. 강화학습은 에이전트가 보상이라는 기준에 따라 환경과 상호작용하며 보상을 최대로 얻어내는 과정을 따른다.\n",
        "- O\n",
        "\n",
        "2. MDP의 구성요소와 그 역할과 알맞게 짝지어지지 않은 것은 몇 번인가요?\n",
        "1) 보상함수 : 에이전트가 특정 상태에서 특정 행동을 했을 때 주어지는 보상의 기댓값을 정의하는 함수\n",
        "2) 환경 : 의사결정을 하는 주체\n",
        "3) 상태 : 에이전트가 의사 결정을 하기 위한 관측값, 보상 등을 가공한 것\n",
        "4) 행동 : 에이전트가 의사결정을 통해 취할 수 있는 것\n",
        "5) 관측 : 환경에서 제공해 주는 정보로 시각적, 수치적 관측으로 나누어진다.\n",
        "- 2\n",
        "\n",
        "3. _ _ _ 은 초기상태에서 에이전트가 미래에 받을 보상을 현재 가치로 환산하여 효율적인 판단을 할 수 있도록 하는 값으로 0과 1사이의 값으로 구성된다.\n",
        "- 감가율"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMYjES2W9NW8",
        "colab_type": "text"
      },
      "source": [
        "4주차 5강 - 강화학습[2]\n",
        "\n",
        "무작위 탐색 방법 - 에이전트가 취할 수 있는 행동 중 하나를 임의로 선택하는 단순한 기법, 에이전트가 더 다양한 경험을 하도록 유도\n",
        "하지만, 에이전트가 너무 다양한 경험만을 추구하는 것도 그리 좋은 방향은 아닌데, 넓은 환경에서는 많은 시간이 걸릴 수 있기에 어느 정도는 에이전트가 학습한 대로 행동하는 것도 필요\n",
        "\n",
        "활용 - 학습된 결과에 따라 에이전트의 행동을 결정하는 기법\n",
        "활용의 기본적인 방법의 하나 탐욕적 방법\n",
        "\n",
        "탐욕적 방법 - 주어진 시점에 에이전트가 가장 큰 보상을 줄 것이라고 기대하는 행동만을 선택\n",
        "단 한 번의 행동에 대해 최대의 보상을 원한다면 활용이 바람직하지만 장기적으로 보상의 총합을 키우기 위해서는 탐험이 좋은 경우가 있음\n",
        "\n",
        "불확실하다는 건 비 탐욕적 행동 가운데 적어도 하나는 탐욕적 보다 더 좋을 것 같지만 정확히 어떤 행동이 그러한지를 모르는 경우를 의미\n",
        "그래서 미래에 남아있는 많은 단계에 대해 행동을 선택해야 한다면, 비 탐욕적 행동을 탐험하여 어떠한 것이 탐욕적 행동보다 좋은 것인지를 찾아내는 것이 더 좋음\n",
        "\n",
        "탐험을 하는 동안 단기적으로는 보상이 적을 지라도 탐험을 통해 더 좋은 행동을 찾아내고 그것을 많이 활용함으로써 장기적으로는 더 큰 보상을 누릴 수 있음\n",
        "\n",
        "하나의 행동을 선택할 때, 활용과 탐험을 동시에 할 수 없기 때문에 이것은 종종 활용과 탐험의 딜레마 혹은 갈등으로 불리게 됨\n",
        "\n",
        "활용이 좋을지, 탐험이 좋은지는 정밀한 가치 추정 값과 불확실성, 앞으로 남아있는 단계의 개수에 따라 복잡한 방법으로 결정\n",
        "\n",
        "행동가치방법 - 행동의 가치를 추정하고 추정 값으로 부터 행동을 선택하도록 하는 방법\n",
        "\n",
        "어떤 행동이 갖는 가치의 참값은 행동이 선택될 때의 평균 보상이며, 참값을 추정하는 방법은 실제로 받은 보상의 산술평균을 계산하는 것 \n",
        "\n",
        "조건 서술어 - 참이면 1, 거짓이면 0의 값을 가지는 확률변수\n",
        "\n",
        "행동이 갖는 가치\n",
        "Qt(a)= 시각t이전에 취해지는 행동a에 대한 보상의 합 / 시각 t이전에 행동 a를 취하는 횟수\n",
        "\n",
        "만약 식의 분모가 0이어서 계산을 할 수 없을 때는 0과 같은 어떠한 기본값으로 정의하고, 분모가 무한으로 커지게 된다면 큰 수의 법칙에 따라 행동의 실제 가치로 접근\n",
        "\n",
        "가장 간단한 행동 선택 규칙 - 추정 가치가 최대인 행동 중 하나를 선택하는 것 = 탐욕적 행동 중 하나를 선택하는 것\n",
        "\n",
        "탐욕적 행동을 대체할만한 한 가지\n",
        "입실론 탐욕적 방법 - 단순한 대안은 대부분의 사간동안에는 탐욕적 선택을 수행하고 정말 가끔 한번씩 상대적 빈도수를 작은 값으로 유지하면서 탐욕적 선택 대신 모든 행동을 대상으로 무작위 선택을 하는 것\n",
        "이때 모든 행동이 선택될 확률은 균등하며, 행동 선택은 행동 가치 추정과는 무관하게 이루어짐\n",
        "\n",
        "1. 에이전트가 다양한 경험을 할 수 있도록 에이전트의 행동을 결정하는 기법은 무엇인가요?\n",
        "- 탐험\n",
        "\n",
        "2. 학습된 결과에 따라 에이전트의 행동을 결정하는 기법은 무엇인가요?\n",
        "- 활용\n",
        "\n",
        "3. 하나의 행동을 선택할 때, 활용과 탐험을 동시에 할 수 없기 때문에 이것은 종종 _ _으로 불리게 된다.\n",
        "- 갈등"
      ]
    }
  ]
}